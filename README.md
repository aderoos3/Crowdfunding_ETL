# Crowdfunding_ETL
## Project 2

For this project, the goal was to extract, transform, and load a few data sets together to make it easier to analyze. The project began with two Excel spreadsheets and a jupyter notebook. For the dependencies were imported, and one of the Excel files was read in and made into a DataFrame using Pandas. I got the info for the DataFrame so I knew what datatypes I was working with. In the DataFrame, there was a column called "category/sub-category" and I wanted to split that into two columns. I used the split function and then a print statement to verify it worked and get all the unique values for each column. I got the number of values and created a list with cat and a number for the category column and scat and a number for the sub-category column. These lists will be used later as the id columns. I made a DataFrame with category and sub-category and exported the csv files of each DataFrame. 

The next part was taking the beginning DataFrame and making it easier to work with. I renamed some column titles to make it easier to understand and changed the date format to datetime and other columns to float datatypes. With the first DataFrame, I merged the category and sub-category DataFrames so there was one big DataFrame. I dropped unwanted columns and exported it as the csv files. Using the other Excel file I read in some data into a DataFrame. I started make making a dictionary iterating through all the rows and then made the DataFrame. I checked the datatypes and split some of the columns. I reordered the columns and exported the csv files. This was the first option, which used json. 

The next part of the project was to create an ERD with all the csv files. The ERD would should the relationships between the tables. The campaign csv file had the id column from all the other csv files which made the campaign table have a few foregin keys. This was a small step to help understand the SQL code. The SQL code was provided. I ran the code to create the columns and then imported the csv files into the tables in Postgres. 

Overall, there were three stages to the project. The python stage, ERD stage and SQL stage. All this made the raw Excel data easier to work with in a database. If needed, the SQL code can be added to a new juptyer notebook for easier analysis in the future. 
